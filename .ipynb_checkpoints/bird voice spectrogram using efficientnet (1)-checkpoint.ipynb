{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21deebd2",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d398c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imorting necessary libraries\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "%config Completer.use_jedi = False\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import glob\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "# from keras import backend as K\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from matplotlib import pyplot\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.metrics as metrics\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import ResNet50V2, ResNet50, EfficientNetB7\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall, Accuracy, BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "import os\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "# enable accelerated linear algebra\n",
    "tf.config.optimizer.set_jit(True)\n",
    "# enable tensorflow AUTOTUNE\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8606b59d",
   "metadata": {},
   "source": [
    "## Is there any GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6978da9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb087b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93605b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 40\n",
    "BATCH = 64\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1664367",
   "metadata": {},
   "source": [
    "## Total Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9043fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import splitfolders  # or import split_folders\n",
    "\n",
    "# input_folder = 'C:/Users\\Ali/Desktop/Bird Voice Classification/spectrgram_dataset/'\n",
    "# out_folder = 'C:/Users\\Ali/Desktop/Bird Voice Classification/splited/'\n",
    "# splitfolders.ratio(input_folder, output=\"data3\", seed=1337, ratio=(.8, .1, .1), group_prefix=None) # default values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94963bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"C:/Users/Ali/Desktop/Bird Voice Classification/spectrorgam_splited/train/\"\n",
    "test_dir = \"C:/Users/Ali/Desktop/Bird Voice Classification/spectrorgam_splited/test/\"\n",
    "val_dir = \"C:/Users/Ali/Desktop/Bird Voice Classification/spectrorgam_splited/val/\"\n",
    "# num_abnormal = len(os.listdir(os.path.join(train_dir, 'Abnormal')))\n",
    "# num_normal = len(os.listdir(os.path.join(train_dir, 'Normal')))\n",
    "# print(f\"Abnormal= {num_abnormal}\")\n",
    "# print(f\"Normal= {num_normal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de507c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantity_tr = {} \n",
    "quantity_te = {}\n",
    "for folder in os.listdir(train_dir):\n",
    "    quantity_tr[folder] = len(os.listdir(train_dir+folder))\n",
    "\n",
    "for folder in os.listdir(test_dir):\n",
    "    quantity_te[folder] = len(os.listdir(test_dir+folder))\n",
    "    \n",
    "quantity_train = pd.DataFrame(list(quantity_tr.items()), index=range(0,len(quantity_tr)), columns=['class','count'])\n",
    "quantity_test = pd.DataFrame(list(quantity_te.items()), index=range(0,len(quantity_te)), columns=['class','count'])\n",
    "\n",
    "figure, ax = plt.subplots(1,2,figsize=(20,5))\n",
    "sns.barplot(x='class',y='count',data=quantity_train,ax=ax[0])\n",
    "sns.barplot(x='class',y='count',data=quantity_test,ax=ax[1])\n",
    "\n",
    "print(\"Number of images in the train set : \", sum(quantity_tr.values()))\n",
    "print(\"Number of images in the test set ; \",sum(quantity_te.values()))\n",
    "number_of_images_in_prediction_set = len(os.listdir(test_dir))\n",
    "print(\"Number of images in prediction set : \",number_of_images_in_prediction_set)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60954ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_history(history, model_name):\n",
    "    #convert the history.history dict to a pandas DataFrame:     \n",
    "    hist_df = pd.DataFrame(history.history) \n",
    "\n",
    "    # save to json:  \n",
    "    hist_json_file = model_name+'_history.json' \n",
    "    with open(hist_json_file, mode='w') as f:\n",
    "        hist_df.to_json(f)\n",
    "\n",
    "    # or save to csv: \n",
    "    hist_csv_file = model_name+'_history.csv'\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "        \n",
    "def plot_accuracy_from_history(history, isinception=False):\n",
    "    color = sns.color_palette()\n",
    "    if(isinception == False):\n",
    "        acc = history.history['acc']\n",
    "        val_acc = history.history['val_acc']\n",
    "    else:\n",
    "        acc = history.history['accuracy']\n",
    "        val_acc = history.history['val_accuracy']\n",
    "    \n",
    "\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    sns.lineplot(epochs, acc, label='Training Accuracy')\n",
    "    sns.lineplot(epochs, val_acc,label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_loss_from_history(history):\n",
    "    color = sns.color_palette()\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    epochs = range(len(loss))\n",
    "    \n",
    "    sns.lineplot(epochs, loss,label='Training Loss')\n",
    "    sns.lineplot(epochs, val_loss, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.show()\n",
    "    \n",
    "def do_history_stuff(history, history_file_name, isinception=False):\n",
    "    save_history(history, history_file_name)\n",
    "    plot_accuracy_from_history(history, isinception)\n",
    "    plot_loss_from_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f72eb45",
   "metadata": {},
   "source": [
    "# Data Loading using Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccacbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the batch size for the generator and training\n",
    "BATCH_SIZE = 96\n",
    "# Declare an image generator for image augmentation\n",
    "datagen = ImageDataGenerator(rescale=1 / 255.0,\n",
    "                                preprocessing_function=preprocess_input,\n",
    "                                rotation_range=10,\n",
    "                                zoom_range=0.2,\n",
    "                                width_shift_range=0.05,\n",
    "                                height_shift_range=0.05,\n",
    "                                shear_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                fill_mode=\"nearest\",\n",
    "                            )\n",
    "# preprocessing_function=preprocess_input,\n",
    "# Declare an image generator testing without generation\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  preprocessing_function=preprocess_input)#preprocessing_function=preprocess_input\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    shuffle=True) # set as training data\n",
    "\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    val_dir, # same directory as training data\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    shuffle=True) \n",
    "\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecd7646",
   "metadata": {},
   "source": [
    "## Visulize some sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8aba66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inv_map_classes = {v: k for k, v in val_gen.class_indices.items()}\n",
    "print(val_gen.class_indices)\n",
    "print(inv_map_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e0447",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_x, t_y = next(train_gen)\n",
    "fig, m_axs = plt.subplots(2, 4, figsize = (16, 8))\n",
    "for (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n",
    "    c_ax.imshow(c_x[:,:,0], cmap = 'gray',)# vmin = -127, vmax = 127\n",
    "    c_ax.set_title('%s' % ('Spec Images' if c_y>0.5 else 'Spectrum'))\n",
    "    c_ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80c92e0",
   "metadata": {},
   "source": [
    "# Custom Metrics to Review Model Performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2fbf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    f1 = 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "    return f1\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    param:\n",
    "    y_pred - Predicted labels\n",
    "    y_true - True labels \n",
    "    Returns:\n",
    "    Specificity score\n",
    "    \"\"\"\n",
    "    neg_y_true = 1 - y_true\n",
    "    neg_y_pred = 1 - y_pred\n",
    "    fp = K.sum(neg_y_true * y_pred)\n",
    "    tn = K.sum(neg_y_true * neg_y_pred)\n",
    "    specificity = tn / (tn + fp + K.epsilon())\n",
    "    return specificity\n",
    "\n",
    "# precision = tf.keras.metrics.Precision()\n",
    "# recall = tf.keras.metrics.Recall()\n",
    "# f1 = tf.keras.metrics.Precision()\n",
    "# auc = tf.keras.metrics.AUC()\n",
    "# acc = tf.keras.metrics.Accuracy()\n",
    "# specificity = specificity()\n",
    "# specificity = keras.metrics.SpecificityAtSensitivity(0.5)\n",
    "# sensitivity = keras.metrics.SensitivityAtSpecificity(0.5)\n",
    "\n",
    "\n",
    "metric = ['accuracy', precision_m, recall_m, f1_m]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a075c965",
   "metadata": {},
   "source": [
    "# Setup Different Call Backs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a323e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deb4272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Create a function to build a TensorBoard callback\n",
    "def create_tensorboard_callback():\n",
    "    # Create a log directory for storing TensorBoard logs\n",
    "    log_dir = \"C:/Users/Ali/Desktop/Bird Voice Classification/spectrorgam_splitedmodels/logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, update_freq='epoch', profile_batch=0)# <-- default value is 2)\n",
    "    return tensorboard_callback\n",
    "\n",
    "# Create new TensorBoard session everytime we train a model\n",
    "tensorboard = create_tensorboard_callback()\n",
    "\n",
    "\n",
    "# Calculate the number of steps for training and validation\n",
    "train_steps = train_gen.samples // BATCH_SIZE\n",
    "val_steps = val_gen.samples // BATCH_SIZE\n",
    "print('[INFO] Training Step Size: ', train_steps)\n",
    "print('[INFO] Validation Step Size: ', val_steps)\n",
    "\n",
    "\n",
    "\n",
    "# Set up exponential learning rate decay\n",
    "def lr_decay(epoch):\n",
    "    \"\"\"\n",
    "    Create a learning rate reduction scheduler\n",
    "    \n",
    "    Arguments:\n",
    "        epoch (int): The index of the current epoch        \n",
    "        \n",
    "    Returns:\n",
    "        lr (float): Learning rate as of epoch\n",
    "    \"\"\"\n",
    "    \n",
    "    initial_lr = 0.005  \n",
    "    lr = initial_lr * np.exp(-0.1 * epoch)\n",
    "    return lr\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "\n",
    "filepath = \"C:/Users/Ali/Desktop/Bird Voice Classification//spectrorgam_splited/models/efficient_spectrum-{epoch:02d}.hdf5\"\n",
    "checkpoint = ModelCheckpoint('C:/Users/Ali/Desktop/Bird Voice Classification/spectrorgam_splited/models/best_model.h5', monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_decay, 1)\n",
    "\n",
    "csv_logger = CSVLogger(filename='C:/Users/Ali/Desktop/Bird Voice Classification/spectrorgam_splitedmodels/models/efficient_spectrum.csv')\n",
    "\n",
    "call_backs = [lr_scheduler, checkpoint, tensorboard, csv_logger, early_stopping ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd10b441",
   "metadata": {},
   "source": [
    "# Check Generator Input Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1afda38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Generator Shape\n",
    "img, label = next(train_gen)\n",
    "print(\"The shape of img:\",img.shape)\n",
    "print(\"The shape of label:\",label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75769151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Val Generator Shape\n",
    "img, label = next(val_gen)\n",
    "print(\"The shape of img:\",img.shape)\n",
    "print(\"The shape of label:\",label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc038118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Generator Shape\n",
    "img, label = next(test_gen)\n",
    "print(\"The shape of img:\",img.shape)\n",
    "print(\"The shape of label:\",label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e436587",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf65e4f",
   "metadata": {},
   "source": [
    "# Solving Class Imbalnce Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae21484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use weight balncing to perform class Imbalnce Problem \n",
    "from collections import Counter\n",
    "counter = Counter(train_gen.classes)                          \n",
    "max_val = float(max(counter.values()))       \n",
    "class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}  \n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da67029",
   "metadata": {},
   "source": [
    "# Optimizer Intilization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67ff37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.005, amsgrad=True, name='Adam',)\n",
    "adamax = tf.keras.optimizers.Adamax(learning_rate=0.005, )\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=0.005, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "rms = tf.keras.optimizers.RMSprop(learning_rate=0.005)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b57983",
   "metadata": {},
   "source": [
    "# Transfer Learning using EfficientNetB7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896f8713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation,GlobalMaxPooling2D\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "\n",
    "image_size = 40\n",
    "input_shape = (image_size, image_size, 3)\n",
    "pre_trained_model = tf.keras.applications.EfficientNetB7(input_shape=input_shape, include_top=False, weights=\"imagenet\")\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "gap = keras.layers.GlobalAveragePooling2D()(pre_trained_model.output, training=False)\n",
    "output = keras.layers.Dense(131, activation='sigmoid')(gap)\n",
    "model = keras.Model(inputs=pre_trained_model.input, outputs=output)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics='accuracy')#'accuracy'\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5f992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lnum, layer in enumerate(model.layers):\n",
    "    print('layer: {}, name:{}, \\t\\t\\ttrainable:{}, dtype: {}'.format(lnum, layer.name, layer.trainable, layer.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b022c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import plot_model\n",
    "\n",
    "\n",
    "# # See graphical representation of the model\n",
    "# plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c19719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which layers are going to be trained\n",
    "for index, layer in enumerate(model.layers):\n",
    "    print(\"Layer: {}, Trainable: {}\".format(index, layer.trainable))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2a4ad5",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce359df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_gen,\n",
    "                            epochs=50,     \n",
    "                            class_weight=class_weights,\n",
    "                            steps_per_epoch=train_steps,                    \n",
    "                            validation_data=val_gen,\n",
    "                            validation_steps=val_steps,                    \n",
    "                            shuffle=True,\n",
    "                            callbacks=call_backs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1897a6",
   "metadata": {},
   "source": [
    "# Model History Acc vs Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cd6f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 16))\n",
    "\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val_Loss')\n",
    "plt.title('Loss Function Evolution')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val_Accuracy')\n",
    "plt.title('Accuracy Function Evolution')\n",
    "plt.legend()\n",
    "\n",
    "# plt.subplot(4, 2, 3)\n",
    "# plt.plot(history.history['precision_m'], label='Precision')\n",
    "# plt.plot(history.history['val_precision_m'], label='val_Precision')\n",
    "# plt.title('Precision Function Evolution')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(4, 2, 4)\n",
    "# plt.plot(history.history['recall_m'], label='Recall')\n",
    "# plt.plot(history.history['val_recall_m'], label='Val_Recall')\n",
    "# plt.title('Recall Function Evolution')\n",
    "# : 0.8198 - f1_m\n",
    "# plt.subplot(4, 2, 5)\n",
    "# plt.plot(history.history['specificity'], label='Specificity')\n",
    "# plt.plot(history.history['val_specificity'], label='Val_specificity')\n",
    "# plt.title('Specificity Function Evolution')\n",
    "\n",
    "# plt.subplot(4, 2, 6)\n",
    "# plt.plot(history.history['f1_m'], label='F1')\n",
    "# plt.plot(history.history['val_f1_m'], label='Val_F1')\n",
    "# plt.title('F1 Function Evolution')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a9df26",
   "metadata": {},
   "source": [
    "# Model Evaluation on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4570e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('exp1/resnet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1091c19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the testing generator and then use our trained model to\n",
    "# make predictions on the data\n",
    "\n",
    "print(\"[INFO] evaluating Model...\")\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "results = model.evaluate(test_gen, )\n",
    "print(f'Test Accuracy : {results[1] * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be948270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"[INFO] Generate predictions for samples:\")\n",
    "prediction = model.predict(test_gen, workers=16)\n",
    "print(\"Predictions shape:\", prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17ec8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = prediction.copy()\n",
    "prediction[prediction <= 0.5] = 0\n",
    "prediction[prediction > 0.5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4812bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Accuracy: \", accuracy_score(test_gen.classes, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7fe758",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(test_gen.classes, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613febfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_pred = model.predict(test_gen)\n",
    "y_pred = prediction\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_gen.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = [\"Normal\", \"Abnormal\"]\n",
    "print(classification_report(test_gen.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872abd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_gen.classes\n",
    "\n",
    "# Calculate F1 score\n",
    "accuracy = accuracy_score(test_gen.classes, prediction)\n",
    "precision = precision_score(test_gen.classes, prediction)\n",
    "recall = recall_score(test_gen.classes, prediction)\n",
    "f1 = f1_score(test_gen.classes, prediction)\n",
    "print('Accuracy with base test data:', accuracy)\n",
    "print('Precision with base test data:', precision)\n",
    "print('Recall with base test data:', recall)\n",
    "print('F1 with base test data:', f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f332419",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true,prediction)\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "\n",
    "print(\"Recall of the model is {:.2f}\".format(recall))\n",
    "print(\"Precision of the model is {:.2f}\".format(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46cd436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "preds = model.predict(test_gen, workers=16)\n",
    "\n",
    "acc = accuracy_score(y_true, np.round(preds))*100\n",
    "cm = confusion_matrix(y_true, np.round(preds))\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print('CONFUSION MATRIX ------------------')\n",
    "print(cm)\n",
    "\n",
    "print('\\nTEST METRICS ----------------------')\n",
    "precision = tp/(tp+fp)*100\n",
    "recall = tp/(tp+fn)*100\n",
    "print('Accuracy: {}%'.format(acc))\n",
    "print('Precision: {}%'.format(precision))\n",
    "print('Recall: {}%'.format(recall))\n",
    "print('F1-score: {}'.format(2*precision*recall/(precision+recall)))\n",
    "\n",
    "print('\\nTRAIN METRIC ----------------------')\n",
    "print('Train acc: {}'.format(np.round((history.history['accuracy'][-1])*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d0f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.matshow(cm, cmap=plt.cm.Oranges)\n",
    "\n",
    "ax.set_xlabel('Prediction')\n",
    "ax.set_ylabel('True Label')\n",
    "\n",
    "tick_labels = ['Normal', 'Abnormal']\n",
    "\n",
    "ax.set_xticks(range(len(tick_labels)))\n",
    "ax.set_yticks(range(len(tick_labels)))\n",
    "ax.set_xticklabels(tick_labels)\n",
    "ax.set_yticklabels(tick_labels)\n",
    "\n",
    "for i in range(len(tick_labels)):\n",
    "    for j in range(len(tick_labels)):\n",
    "        ax.text(j, i, cm[i, j],\n",
    "               ha='center', va='center')\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27621baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c08082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "fpr, tpr, _ = roc_curve(y_true, prediction)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"ROC for this Model:\", roc_auc)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5171211",
   "metadata": {},
   "source": [
    "# AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed1dd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "fpr, tpr, _ = roc_curve(y_true, preds)\n",
    "fig, ax1 = plt.subplots(1,1, figsize = (5, 5), dpi = 250)\n",
    "ax1.plot(fpr, tpr, 'b.-', label = 'ResNet50-Model (AUC:%2.2f)' % roc_auc_score(y_true, preds))\n",
    "ax1.plot(fpr, fpr, 'k-', label = 'Random Guessing')\n",
    "ax1.legend(loc = 4)\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3776e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('/home/xylexa/Desktop/normal_abnormal/finetuned/resnet50/exp1/resnet50_NFT.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c77647e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
